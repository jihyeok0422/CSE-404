{
  "cells": [
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "# Code 2: Perceptron\n\n## Part 1: Scikit-Learn Overview\nScikit-Learn uses the same design principles across its API. This is a brief overview of the format. \n\n### Consistency\nAll objects share a consistent and simple interface.\n\n### Estimators\nAny object that estimates parameters based on a dataset is called an *estimator*. The estimation is done by the *fit( )* method which takes a dataset (and labels for a supervised algorithm) as a parameter. All other parameters used to guide the estimation are called *hyperparameters*, and these are set as instance variables via a constructor parameter. \n\n### Transformers\nEstimators that can also transform the dataset are called *transformers* (not to be confused with the newest Neural Net Transformer). This is done with the *transform( )* method on the dataset. All transformers also have the *fit_transform( )* method: this is equivalent to calling fit( ) and then transform( ), but is usually optimized to run faster. \n\n### Predictors\nEstimators that are given a dataset and can make predictions on it are called *predictors*. This is done with the *predict( )* method which takes a dataset and returns corresponding predictions. These also have a *score( )* method that measures the quality of the predictions using a test set (and corresponding labels if supervised). \n\n### Inspection\nAll the estimator's hyperparameters are accesible through public instance variables (e.g., imputer.strategy) and its learned parameters are accessible through public instance variables with an underscore suffix (e.g., imputer.statistics_). \n\n### Use of other packages\nScikit-Learn uses other packages rather than create its own classes. Datasets are represented as NumPy arrays or SciPy matrices. Hyperparameters are Python strings or numbers. \n\n### Default Parameters\nScikit-Learn starts with typical default values for most parameters. "
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Part 2: Basic Perceptron\nLet's code a perceptron using Scikit-Learn!\nYour job is to consult the Scikit-Learn API and fill in the skeleton code. "
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# imports\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import Perceptron",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "eager_nott",
        "starter_code": "# Load the iris dataset\n# It consists of 3 different types of irises’ (Setosa, Versicolour, & Virginica) \n#     petal & sepal length, stored in a 150x4 numpy.ndarray.\n#     Rows: samples \n#     Columns: Sepal Length, Sepal Width, Petal Length & Petal Width.\niris = ",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Load the iris dataset\n# It consists of 3 different types of irises’ (Setosa, Versicolour, & Virginica) \n#     petal & sepal length, stored in a 150x4 numpy.ndarray.\n#     Rows: samples \n#     Columns: Sepal Length, Sepal Width, Petal Length & Petal Width.\niris = ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "red_var",
        "starter_code": "# Split the dataset into X (features) and y (labels)\n# X: should contain all rows, but only the petal length & petal width features\nX = \n\n# y: Setosa is our target\ny = \n\nprint(X)\nprint(y)",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Split the dataset into X (features) and y (labels)\n# X: should contain all rows, but only the petal length & petal width features\nX = \n\n# y: Setosa is our target\ny = \n\nprint(X)\nprint(y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "big_hel",
        "starter_code": "# Create an instance of a Perceptron classifier\nper_clf = \n",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create an instance of a Perceptron classifier\nper_clf = \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "calm_tyr",
        "starter_code": "# Use the Perceptron's fit method on your smaller dataset\nper_clf.",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Use the Perceptron's fit method on your smaller dataset\nper_clf.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "blue_oor",
        "starter_code": "# Use the Perceptron's predict method on sample[2,0.5]\ny_pred = \n\nprint(y_pred)",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Use the Perceptron's predict method on sample[2,0.5]\ny_pred = \n\nprint(y_pred)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Part 3: Another Perceptron"
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# import Scikit-Learn's StandardScaler, train_test_split, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "stoic_vali",
        "starter_code": "# Save the iris dataset data and target values to X and y, respectively\nX = \ny = ",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Save the iris dataset data and target values to X and y, respectively\nX = \ny = ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "green_vali",
        "starter_code": "# Print/view the first 5 observations from y\n",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Print/view the first 5 observations from y\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "blue_magni",
        "starter_code": "# Print/view the first 10 observations of X\n",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Print/view the first 10 observations of X\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "green_mani",
        "starter_code": "# Split the dataset into 80% training and 20% testing\nX_train, X_test, y_train, y_test = ",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Split the dataset into 80% training and 20% testing\nX_train, X_test, y_train, y_test = ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "gray_sol",
        "starter_code": "# Train the StandardScaler to format the X training set\n# Remember StandardScaler standardizes all features to have\n#     mean = 0 and unit variance\nsc = \nsc.",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Train the StandardScaler to format the X training set\n# Remember StandardScaler standardizes all features to have\n#     mean = 0 and unit variance\nsc = \nsc.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "calm_sif",
        "starter_code": "# Apply the StandardScaler to the X training dataset\nX_train_std = \n\n# Apply StandardScaler to X test data\nX_test_std = \n",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Apply the StandardScaler to the X training dataset\nX_train_std = \n\n# Apply StandardScaler to X test data\nX_test_std = \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "fit_thor",
        "starter_code": "# Create a Perceptron object with parameters:\n#     50 iterations (epochs) over the dataset\n#     learning rate n = 0.1\n#     random_state = 0\nper = \n\n# Train the Perceptron on the standardized X training set\nper.",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create a Perceptron object with parameters:\n#     50 iterations (epochs) over the dataset\n#     learning rate n = 0.1\n#     random_state = 0\nper = \n\n# Train the Perceptron on the standardized X training set\nper.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "aged_saga",
        "starter_code": "# Apply trained Perceptron on standardized X test dataset to make predictions for y\ny_pred = \n\n# Print predictions\n",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Apply trained Perceptron on standardized X test dataset to make predictions for y\ny_pred = \n\n# Print predictions\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "sly_odin",
        "starter_code": "# Print true labels\n\n",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Print true labels\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "state": "graded",
        "deletable": false,
        "id": "green_nott",
        "starter_code": "# Print the accuracy_score of the model \n# You should compare the actual labels with the predicted labels\nprint(\"Accuracy: %.2f\" )",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Print the accuracy_score of the model \n# You should compare the actual labels with the predicted labels\nprint(\"Accuracy: %.2f\" )",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "mimir": {
      "project_id": "6ea053f9-2d48-42db-8107-a05feddc3ec3",
      "last_submission_id": "",
      "data": {}
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}